---
student_name: Théo BERVILLER
topic: [The digital Commons in the Age of AI over-extraction]
---

---

## Introduction
For decades, the digital commons, which is composed of Free and Open Source Software, open data libraries, and collaborative knowledge, has served as the core of our digital infrastructure, because almost all of it relies on it. This ecosystem relies on the “Open by Default” principle, which assumes that non-rivalrous access creates a rising tide for all participants, leading to a snowball effect that exacerbates and sustains the digital commons.

However, scholars such as Longpre et al. (2024) emphasize that we are witnessing the “closing of the open web” as a reaction to predatory extraction. Indeed, there are several reasons leading to that unfortunate end, but for instance, generative AI “scraper swarms” are harvesting these commons at a scale that threatens their sustainability and transforms them into proprietary assets, which depreciates and disincentivises investment in FOSS projects by volunteers.


## 1. The Structural Conflict: From Cooperation to Extraction
This problem that the digital commons is facing emerged first through what authors like Huang and Siddarth (2023) describe as the “Paradox of Reuse”, which is basically the one-way extraction of open-source knowledge. Indeed, while Big Tech firms are the largest contributors to the commons, their involvement is often a strategic move to “incorporate” the commons into their capitalist production and be the only ones to draw benefits from it.

First, there is an incentive collapse. The same authors argue that AI models degrade digital commons by discouraging human contribution. For instance, Burtch & Lee (2024) note that activity on Stack Overflow has decreased by 12% after ChatGPT’s release in 2022.
On top of a drop in contribution, scholars (LaCroix & Mohseni, 2022) demonstrate that AI firms act as rational actors who, when possible, will do as much as possible to decrease their costs or profit from someone else’s work. AI private companies will free-ride on shared resources, leading to a “Tragedy of the AI Commons”, resulting in the progressive degradation of the shared digital ecosystem as private gain exhausts the collective resource.
Finally, O’Neil et al. (2021) explain that even though corporate participation amounts to 73% of FOSS projects, in the end, their productivity dips on weekends, while volunteer labour remains constant. On top of being the unpaid subsidy that is the backbone of private companies, it is also now being harvested to train proprietary models without reciprocity. Indeed, firms are using the “SaaS loophole” to profit from the commons without any reciprocity obligations of open licenses, which is unfair, but mainly a form of “enclosure” now standard in AI training.

## 2. The Opacity Risk: “Black Box” Governance and Bias
After reviewing the progressive deliquescence of digital commons participation by private companies, another significant concern for public policy is the shift from transparent common resources to opaque proprietary models and tools. Indeed, as Urvashi & Chamuah (2021) established, Big Tech’s power is defined by data-centricity and an “infrastructural role” that allows it to gatekeep control over cloud computing and AI ecosystems.

Such power leads to an opaque ingestion of data by AI companies. Indeed, Dikow et al. (2023) emphasise the struggle of public institutions (GLAM in the paper) to provide data for research without having it captured by “black box” algorithms with opaque filtering and processing methods that can modify the meaning and the end-use of the data provided.
Thus, there is a concrete risk of reputational and ethical harm. The OECD (2025), in its report, emphasises that governments have a “special responsibility” to avoid tools that produce biased results. Indeed, if the government allows its open data to be ingested by models like Google Vision (that produce inaccurate or racist outputs), it will discredit the credibility and integrity of the public source and the communities it represents.
In the end, we are entering a “technofeudal” era, in which the public maintains the data, but owns the “manor” and charges rent for insights derived from public labour.


## Policy Recommendations: Toward Mandatory Reciprocity
To protect our sovereignty, the government must move toward a framework of governed reciprocity:
1. Following OECD principles enumerated in its report, any AI models trained on public data must provide a transparency manifest whenever public authorities require it, to ensure the methods used do not introduce algorithmic bias.
2. Large-scale private companies should fund the maintenance of the digital commons infrastructure they use, proportionally to their extraction, ensuring the sustainability of essential libraries.
3. To mitigate “governance capture”, public code and data must be hosted on publicly managed and sovereign infrastructure rather than proprietary and foreign clouds.


## Conclusion
To conclude, digital commons are threatened by “pollution” and “undersupply” if nothing is done in the short term. Indeed, if we allow opaque, one-sided harvesting to continue, we risk the collapse of the infrastructure on which our digital economy depends. The state must ensure that the value extracted from the commons is returned through transparency, mandatory maintenance, and sovereign control.

---

# Bibliography

BIRKINBINE, Benjamin. (2020). Incorporating the Digital Commons: Corporate Engagement with Free and Open Source Software. London: University of Westminster Press.

DEL RIO-CHANONA, Maria del Rio, LAURENTSYEVA, Nadzeya, and WACHS, Johannes. (2024). "The consequences of generative AI for online knowledge communities". PNAS Nexus, vol. 3, n° 3.

DULONG DE ROSNAY, Mélanie, and STALDER, Felix. (2020). "Digital commons". Internet Policy Review, vol. 9, n° 4.

EUROPEAN WORKING TEAM ON DIGITAL COMMONS. (2022). Towards a sovereign European digital infrastructure of commons. [Online].

HUANG, Saffron, and SIDDARTH, Divya. (2023). "Generative AI and the Digital Commons". arXiv preprint arXiv:2303.11074.

LACROIX, Travis, and MOHSENI, Aydin. (2022). "The tragedy of the AI commons". Synthese, vol. 200, n° 4.

LONGPRE, Shayne, MAHARI, Robert, et al. (2024). Consent in Crisis: The Rapid Decline of the AI Data Commons. Data Provenance Initiative. [Online].

O’NEIL, Mathieu, CAI, Xiaolan, MUSELLI, Laurent, PAILLER, Fred, and ZACCHIROLI, Stefano. (2021). The coproduction of open source software by volunteers and big tech firms. Canberra: Digital Commons Policy Council (DCPC).

OECD. (2025). Governing with Artificial Interlligence: The State of Play and Way Forward in Core Government Functions. Paris: OECD Publishing.

DIKOW, Rebecca B, C DIPIETRO, Michael Trizna, et al. « Developing responsible AI practices at the Smithsonian Institution », Research Ideas and Outcomes. 25 octobre 2023, vol.9.

SIDDARTH, Divya, and WEYL, E. Glen. (2021). "The Case for Digital Commons". World Economic Forum. [Online].


</div>
